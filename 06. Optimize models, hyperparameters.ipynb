{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgeZAgmF_Lx5"
      },
      "source": [
        "# **Optimize models: Tuning Hyperparameters**\n",
        "---\n",
        "> This notebook entails optimizing the performance of the models in the previous notebook by tuning / optimizing model **hyper-parameters**\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8FrP_6lGIAv"
      },
      "source": [
        "> The _estimators_ used in this learning path so far have a wide range of parameters that control how machine learning models are trained.\n",
        ">> + **Parameters** - Values that can be determined from the data  \n",
        ">> + **Hyperparameters** - More correctly,  values that you specify to affect the behavior of a training algorithm\n",
        "\n",
        "> Models can have many hyperparameters and finding the best combination of parameters can be treated as a search problem.  \n",
        "\n",
        "> Often, you don't immediately know what the optimal model architecture should be for a given model, and thus you'd like to be able to explore a range of possibilities.\n",
        "\n",
        "> In a true machine learning fashion, you'll ideally ask the machine to perform this exploration and select the optimal model architecture automatically\n",
        "\n",
        "> Fortunately, [`SciKit-Learn`](https://scikit-learn.org/stable/index.html) provides ways to tune hyperparameters by trying multiple combinations and finding the best result for a given performance metric. This can be achieved through:\n",
        ">> + [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) - Exhaustive search over specified parameter values for an estimator.  \n",
        ">> + [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) - Randomized search on hyper parameters   \n",
        ">> + [`Optuna`](https://optuna.readthedocs.io/en/stable/index.html) - An automatic hyperparameter optimization software framework, particularly designed for machine learning (not provided by Scikit-Learn)\n",
        ">> + [`BayesSearchCV`](https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL_TT0qQeD-W"
      },
      "source": [
        "## `GridSearchCV`\n",
        "> `GridSearchCV` performs an exhaustive search over a specified grid of hyperparameters. For each combination of hyperparameters specified in the grid, GridSearchCV trains a new model and evaluates its performance using cross-validation.\n",
        "\n",
        "> For example, if you have two hyperparameters, each with three possible values, `GridSearchCV` will try all 3x3=9 combinations of these hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqEC0fz-jJ3y"
      },
      "source": [
        "> Parameters (a few of the most important):\n",
        "+ **estimator** - estimator object  \n",
        "+ **param_grid: dict or list of dictionaries** - Dictionary with parameters names (str) as keys and lists of parameter settings to try as values, or a list of such dictionaries     \n",
        "+ **n_jobs: int, default=None** - Number of jobs to run in parallel. `None` means `1` unless in a `joblib.parallel_backend` context. `-1` means using all processors  \n",
        "+ **cv: int, cross-validation generator or an iterable, default=None (5)**  \n",
        "+ **scoring: str, callable, list, tuple or dict, default=None** - Strategy to evaluate the performance of the cross-validated model on the test set.  \n",
        "+ **return_train_score: bool, default=False** - If `False`, the `cv_results_` attribute will not include training scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive  \n",
        "\n",
        "> Attributes are listed and explained [`here`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) on the documentation page\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3W-taXAeIKJ"
      },
      "source": [
        "## `RandomizedSearchCV`  \n",
        "> While `GridSearchCV` exhaustively searches through all combinations of hyperparameters specified in a grid, `RandomizedSearchCV` samples a fixed number of hyperparameter settings from specified probability distributions.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ `RandomizedSearchCV` is more efficient than `GridSearchCV` when the hyperparameter search space is large. Since it doesn't try every single combination, it can explore a broader range of values in a shorter amount of time.\n",
        "+ When the search space is huge and it's impractical to try every possible combination, `RandomizedSearchCV` provides a more feasible alternative.\n",
        "+ The `n_iter` parameter specifies the number of parameter settings that are sampled  \n",
        "+ It is highly recommended to use **continuous distributions** for continuous parameters."
      ],
      "metadata": {
        "id": "0zv29ZVUMeba"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys7ArOJQofRV"
      },
      "source": [
        "> Parameters (a few of the most important):\n",
        "+ **estimator** - estimator object  \n",
        "+ **param_distributions: dict or list of dicts** - Dictionary with parameters names (`str`) as keys and distributions or lists of parameters to try. Distributions _must_ provide a `rvs` method for sampling (such as those from `scipy.stats.distributions`)   \n",
        "+ **n_jobs: int, default=None** - Number of jobs to run in parallel. `None` means `1` unless in a `joblib.parallel_backend` context. `-1` means using all processors  \n",
        "+ **n_iter: int, default=10** - Number of parameter settings that are sampled. `n_iter` trades off runtime vs quality of the solution.  \n",
        "+ **cv: int, cross-validation generator or an iterable, default=None (5)**  \n",
        "+ **scoring: str, callable, list, tuple or dict, default=None** - Strategy to evaluate the performance of the cross-validated model on the test set.  \n",
        "+ **random_state: int, RandomState instance or None, default=None** - Pass an int for reproducible output across multiple function calls.\n",
        "+ **return_train_score: bool, default=False** - If `False`, the `cv_results_` attribute will not include training scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive  \n",
        "\n",
        "> Attributes are listed and explained [`here`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) on the documentation page"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [`Optuna`](https://optuna.readthedocs.io/en/stable/index.html)  \n",
        "> Steps for hyperparameter tuning using optuna are as follows:\n",
        "+ Define an `objective` function that that `optuna` will `optimize` - This function takes a set of hyper-parameters as input and returns an evaluation metric that `optuna` aims to `minimize` or `maximize`  \n",
        "+ Using [`optuna.create_study()`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.create_study.html#optuna.create_study), create a [`study`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study) object that represents an optimization task - It contains multiple [`trial`]() corresponding to a single run of the objective function with specified set of hyper-parameters\n",
        "+ `optimize` the `objective` function using [`study.optimize(objective, n_trials = n)`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.optimize)"
      ],
      "metadata": {
        "id": "c9h_6HfHMlou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:**\n",
        "> + The `direction` parameter passed to `optuna.create_study()` will affect the results, as it specifies whether the objective of the optimization is to `maximize` or `minimize` the value returned by the objective function\n",
        ">> * `direction='minimize` - finds the set of hyperparameters that result in the lowest value of the objective function\n",
        ">> * `direction='maxumize` - finds the set of hyperparameters that result in the highest value of the objective function\n",
        "\n",
        "> + [`study.best_params`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.best_params) / `study.best_trial.params` returns only best hyperparameters that had a search space defined using the `trial.suggest...` methods. The study object does not contain hard coded parameters with fixed values throughout the trials - Therefore, find a way to combine them both when training the final model"
      ],
      "metadata": {
        "id": "2jklktK2HMDx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSh9eoQimAwi"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mI7Bre_ClCca"
      },
      "outputs": [],
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load the training dataset\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/daily-bike-share.csv\n",
        "bike_data = pd.read_csv('daily-bike-share.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDMQiIVtlE38"
      },
      "outputs": [],
      "source": [
        "# Extract features / inputs (X) and label (y)\n",
        "# features/inputs (X):\n",
        "cols = ['season','mnth', 'holiday','weekday','workingday','weathersit','temp', 'atemp', 'hum', 'windspeed']\n",
        "X = bike_data[cols].copy()\n",
        "\n",
        "# label (y):\n",
        "y = bike_data['rentals']\n",
        "\n",
        "numeric_features = [6,7,8,9]\n",
        "categorical_features = [0,1,2,3,4,5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CrKg0rllSc2"
      },
      "outputs": [],
      "source": [
        "# import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation / test sets 70% - 30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
        "\n",
        "# Keep in mind that the resultant variables (X_train, X_test, y_train, y_test) are all DataFrames\n",
        "type(X_train) # to confirm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o8uPipKc6Q3"
      },
      "outputs": [],
      "source": [
        "# define function for evaluation model, on VALIDATION DATASET\n",
        "def evaluate_model(model):\n",
        "  from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "  import numpy as np\n",
        "\n",
        "  # Get predictions from the model passed\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # MSE\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  # RMSE\n",
        "  rmse = np.sqrt(mse)\n",
        "  # R-squared\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "  # MAE\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "  print(f\"\\nMSE: {round(mse, 2)}\")\n",
        "  print(f\"MAE: {round(mae, 2)}\")\n",
        "  print(f\"RMSE: {round(rmse, 2)}\")\n",
        "  print(f\"R Squared: {round(r2, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uayksPI-mPhl"
      },
      "source": [
        "## Pre-processing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPbBk_FAmOuJ"
      },
      "outputs": [],
      "source": [
        "# import libraries for pre-processing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCqXbx3Lnd0j"
      },
      "outputs": [],
      "source": [
        "# Encode categorical features\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), #1. handle missing values\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")) # 2. enode\n",
        "])\n",
        "\n",
        "# Scale numerical features\n",
        "num_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")), #1. handle missing values\n",
        "    (\"std_sc\", StandardScaler()) # scale\n",
        "])\n",
        "\n",
        "# Now combine the two transformers (num_transformer & cat_transformer) into one\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"cat\", cat_transformer, categorical_features),\n",
        "    (\"num\", num_transformer, numeric_features)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgJGJnVAkgHN"
      },
      "source": [
        "## [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn-ensemble-randomforestregressor) algorithm  \n",
        "+ `RandomForestRegressor` parameters, their explanations and best practices for tuning are listed in its documentation linked [`here`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn-ensemble-randomforestregressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZQWAErjfK0N"
      },
      "source": [
        "### `RandomizedSearchCV` approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBO48luXLadV"
      },
      "outputs": [],
      "source": [
        "# Define randomized search grid with RandomForestRegressor hyperparameters:\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "param_dist = {\n",
        "    \"reg__max_depth\": randint(3, 10),\n",
        "    \"reg__min_samples_split\": randint(2, 20),\n",
        "    \"reg__min_samples_leaf\": randint(2, 20),\n",
        "    \"reg__max_features\": [\"sqrt\", 1, 0.5],\n",
        "    \"reg__n_estimators\": randint(10, 300, 50)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKgMRaYrJayI"
      },
      "outputs": [],
      "source": [
        "# import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# create a pipeline with preprocessor + RandomForestRegressor\n",
        "forest_pipeline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor), # preprocess\n",
        "    (\"reg\", RandomForestRegressor(random_state=42)) # model\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkYv82__emR9"
      },
      "outputs": [],
      "source": [
        "# import RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Create RandomSearchCV with RandomForestRegressor estimator\n",
        "random_search = RandomizedSearchCV(forest_pipeline,\n",
        "                                   n_iter = 1000,\n",
        "                                   n_jobs = -1,\n",
        "                                   verbose = True,\n",
        "                                   random_state=0,\n",
        "                                   param_distributions=param_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM-KW7xle54R",
        "outputId": "0dd181e9-a396-444c-d26f-063d1f5dcf44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Params: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 9, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 327, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
            "Best Score: 0.751224119860589\n",
            "CPU times: user 37.9 s, sys: 4 s, total: 41.9 s\n",
            "Wall time: 30min 20s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit the data to the random_search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Save best_params to a variable\n",
        "params = random_search.best_estimator_.named_steps[\"reg\"].get_params()\n",
        "\n",
        "print(f\"Best Params: {params}\")\n",
        "print(f\"Best Score: {random_search.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAEYT1xfk6w_",
        "outputId": "b37b1746-89e7-4524-b98f-94704355256f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.52 s, sys: 0 ns, total: 1.52 s\n",
            "Wall time: 1.51 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# create a pipeline with preprocessor + best_estimator_ found after search\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"estimator\", RandomForestRegressor().set_params(**params))\n",
        "])\n",
        "\n",
        "# train model\n",
        "forest_model = pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PWfEy3uhSqY",
        "outputId": "15699f54-1700-4015-f4a0-1d09ecb32f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE: 76480.54\n",
            "MAE: 196.3\n",
            "RMSE: 276.55\n",
            "R Squared: 0.811\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test / validation data\n",
        "evaluate_model(forest_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZDahRkBkxQJ"
      },
      "source": [
        "## [`GradientBoostingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn-ensemble-gradientboostingregressor) algorithm   \n",
        "+ `GradientBoostingRegressor` parameters, their explanations and best practices for tuning are listed in its documentation linked [`here`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQCETQ__n7NG"
      },
      "source": [
        "### `RandomizedSearchCV` approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oR0n-zwj_PP"
      },
      "outputs": [],
      "source": [
        "# Define randomized search grid with GradientBoostingRegressor hyperparameters:\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_dist = {\n",
        "    'reg__n_estimators': randint(50, 500),\n",
        "    'reg__max_depth': randint(3, 10),\n",
        "    'reg__learning_rate': uniform(0.01, 0.5),\n",
        "    'reg__min_samples_split': randint(2, 20),\n",
        "    'reg__min_samples_leaf': randint(1, 20),\n",
        "    'reg__max_features': ['auto', 'sqrt', 'log2']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoZ5vTIkIXja"
      },
      "outputs": [],
      "source": [
        "# import GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Create pipeline with preprocessor + GradientBoostingRegressor\n",
        "gb_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor), # Preprocess data\n",
        "    (\"reg\", GradientBoostingRegressor(random_state = 42)) # Fit model\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R8wbwTyhWPs"
      },
      "outputs": [],
      "source": [
        "# import RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# RandomizedSearchCV object with neessary parameters set\n",
        "random_search = RandomizedSearchCV(gb_pipeline,\n",
        "                              param_distributions = param_dist,\n",
        "                              n_jobs = -1,\n",
        "                              n_iter = 1000,\n",
        "                              cv= 3,\n",
        "                              verbose = True,\n",
        "                                   random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Jl8C7RgFGv",
        "outputId": "2ba2a894-818f-4f2e-fb5c-3a8807c8c57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n",
            "Best Params: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.12336519146175533, 'loss': 'squared_error', 'max_depth': 7, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 15, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 133, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
            "Best Score: 0.7577032939530337\n",
            "CPU times: user 20.3 s, sys: 2.03 s, total: 22.3 s\n",
            "Wall time: 18min 3s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit the data to the random_search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# set best_params_ to a variable\n",
        "params = random_search.best_estimator_.named_steps[\"reg\"].get_params()\n",
        "\n",
        "print(f\"Best Params: {params}\")\n",
        "print(f\"Best Score: {random_search.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1gVtI8iou-y",
        "outputId": "a39a19d6-c688-4eb1-8017-ad405ef78f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 182 ms, sys: 0 ns, total: 182 ms\n",
            "Wall time: 183 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# create a pipeline with preprocessor + best_estimator_ found after search\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"estimator\", GradientBoostingRegressor().set_params(**params))\n",
        "])\n",
        "\n",
        "# train model\n",
        "gb_model = pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fq64cGmhaB8",
        "outputId": "dbe6e9af-cb78-4a24-9b63-ccdabc8ffe29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE: 79684.62\n",
            "MAE: 199.58\n",
            "RMSE: 282.28\n",
            "R Squared: 0.803\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test / validation data\n",
        "evaluate_model(gb_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGKYRy_o9Plp"
      },
      "source": [
        "## [`LGBM`](https://lightgbm.readthedocs.io/en/stable/index.html) algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "f5JaSHLz_oS_"
      },
      "outputs": [],
      "source": [
        "# import LightGBM\n",
        "import lightgbm\n",
        "!pip install --upgrade lightgbm\n",
        "from lightgbm import LGBMRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpFtfUVR79Q1"
      },
      "source": [
        "### [`Optuna`](https://optuna.readthedocs.io/en/stable/index.html) approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ChJIyFJ6QIM"
      },
      "outputs": [],
      "source": [
        "# install and import optuna\n",
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "# disable logging\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# import cross_val_score\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCr7h46s87yd"
      },
      "outputs": [],
      "source": [
        "# Define an objective funciton to be minimized\n",
        "def objective(trial):\n",
        "\n",
        "  # define search space for the hyperparameters:\n",
        "  params = {\n",
        "      'verbosity': 0,\n",
        "      'metric': 'rmse',\n",
        "      'boosting_type': 'gbdt',\n",
        "      'early_stopping': 10,\n",
        "      'max_bin': trial.suggest_int('max_bin', 255, 300),\n",
        "      'num_leaves': trial.suggest_int('num_leaves', 2, 50),\n",
        "      'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
        "      'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
        "      'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
        "      'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 2, 30),\n",
        "      'path_smooth': trial.suggest_int('path_smooth', 2, 10),\n",
        "      'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.1, 0.5),\n",
        "      'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0),\n",
        "      'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0)\n",
        "  }\n",
        "\n",
        "  # model\n",
        "  model = LGBMRegressor()\n",
        "  model.set_params(**params)\n",
        "\n",
        "  # parameter to pass to the fit function of LGBMRegressor\n",
        "  eval = {\n",
        "      'eval_set': [(preprocessor.fit_transform(X_test), y_test)]\n",
        "  }\n",
        "\n",
        "  # get cross_validation_score\n",
        "  score = cross_val_score(model, preprocessor.fit_transform(X_train), y_train,\n",
        "                          fit_params = eval, cv=3, scoring='neg_root_mean_squared_error',\n",
        "                          n_jobs = -1).mean()\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zdZH3a85Rk4",
        "outputId": "ab14cc50-caa7-4a4d-b6b8-1a34f05e2010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'max_bin': 259, 'num_leaves': 5, 'max_depth': 7, 'n_estimators': 946, 'learning_rate': 0.06515796583328963, 'min_data_in_leaf': 2, 'path_smooth': 2, 'min_gain_to_split': 0.14106204260940144, 'reg_lambda': 0.031535305046180864, 'reg_alpha': 0.6083194758643262}\n",
            "Best Value: -342.82891838049113\n",
            "CPU times: user 24.1 s, sys: 382 ms, total: 24.5 s\n",
            "Wall time: 58.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# create a new study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# optimize the objective function\n",
        "study.optimize(objective, n_trials = 200)\n",
        "\n",
        "# save best_params to a variable\n",
        "best_params = study.best_params\n",
        "print(f\"Best Params: {best_params}\")\n",
        "print(f\"Best Value: {study.best_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KPVLItx5LDj"
      },
      "outputs": [],
      "source": [
        "# hard coded parameters\n",
        "hard_coded = {\n",
        "    'metric': 'rmse',\n",
        "    'early_stopping': 10,\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "}\n",
        "\n",
        "# create LGBMRegressor\n",
        "estimator = LGBMRegressor(**hard_coded, **best_params)\n",
        "\n",
        "# define pipeline with pre-processor + LGBMRegressor\n",
        "lgbm_pipeline = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor), # preprocess\n",
        "    (\"lgb\", LGBMRegressor(**best_params)) # estimator\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjLBU1BZ4jAn"
      },
      "outputs": [],
      "source": [
        "lgbm_model = lgbm_pipeline.fit(X_train, y_train,\n",
        "                               lgb__eval_set = [(preprocessor.fit_transform(X_test), y_test)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0HesxHl8mB_",
        "outputId": "118be645-06e5-4aaf-8044-78dc5702a335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
            "[LightGBM] [Warning] min_gain_to_split is set=0.14106204260940144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.14106204260940144\n",
            "\n",
            "MSE: 87546.81\n",
            "MAE: 214.84\n",
            "RMSE: 295.88\n",
            "R Squared: 0.781\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model\n",
        "evaluate_model(lgbm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWApzNfNk15B"
      },
      "source": [
        "## [`XGBRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn-ensemble-gradientboostingregressor) algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgcBws0wzvG6"
      },
      "source": [
        "### `RandomizedSearchCV` approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDp7dl65zzZx"
      },
      "outputs": [],
      "source": [
        "# import r2 score\n",
        "from sklearn.metrics import r2_score\n",
        "# import XGBRegressor\n",
        "from xgboost import XGBRegressor\n",
        "# validation dataset for early stopping\n",
        "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "\n",
        "# Create pipeline with preprocessor + XGBRegressor\n",
        "xgb_pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor), # pre-process\n",
        "    (\"xgb\", XGBRegressor(booster = \"gbtree\",\n",
        "                         random_state = 42,\n",
        "                         #eval_set = eval_set,\n",
        "                         #early_stopping_rounds = 10,\n",
        "                         objective = \"reg:squarederror\",\n",
        "                         eval_metric = r2_score)) # estimator\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVLLhgw_0l8Q"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_dist = {\n",
        "    \"xgb__n_estimators\": randint(100, 1000),\n",
        "    \"xgb__learning_rate\": uniform(0.01, 0.1),\n",
        "    \"xgb__max_depth\": randint(6, 10),\n",
        "    #\"xgb__max_leaves\":[0],\n",
        "    \"xgb__min_child_weight\": randint(1,6),\n",
        "    \"xgb__gamma\": randint(0,5),\n",
        "    \"xgb__subsample\": uniform(0, 1),\n",
        "    \"xgb__colsample_bytree\": uniform(0, 1)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKVRH47X_Uet"
      },
      "outputs": [],
      "source": [
        "# import RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "random_search = RandomizedSearchCV(xgb_pipeline,\n",
        "                                   param_distributions = param_dist,\n",
        "                                   n_jobs = -1,\n",
        "                                   cv = 4,\n",
        "                                   n_iter = 1000,\n",
        "                                   verbose = True,\n",
        "                                   random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqoPEmilCQX1",
        "outputId": "cb4f9170-9286-41f4-ff1e-0ee59cad2a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 1000 candidates, totalling 4000 fits\n",
            "Best Params: {'objective': 'reg:squarederror', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.9365537663271488, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': <function r2_score at 0x7b89a4ba1b40>, 'feature_types': None, 'gamma': 0, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.0289613969338456, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 7, 'max_leaves': None, 'min_child_weight': 3, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 572, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.0799077058806561, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
            "Best Score: 0.7534130297934232\n",
            "CPU times: user 27.4 s, sys: 2.57 s, total: 29.9 s\n",
            "Wall time: 22min 31s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Fit the data to the random_search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# save best_params_ to a variable\n",
        "params = random_search.best_estimator_.named_steps[\"xgb\"].get_params()\n",
        "\n",
        "print(f\"Best Params: {params}\")\n",
        "print(f\"Best Score: {random_search.best_score_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DnH1ktADDz0"
      },
      "outputs": [],
      "source": [
        "# create pipeline with best_params_ model + preprocessor\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor), # preprocess\n",
        "    (\"estimator\", XGBRegressor().set_params(**params)) # model\n",
        "])\n",
        "\n",
        "xgb_model = pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpHXF-KxEWGU",
        "outputId": "ea746b6b-256e-4dac-f50a-7a787773f390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MSE: 76080.42\n",
            "MAE: 201.18\n",
            "RMSE: 275.83\n",
            "R Squared: 0.812\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the XGBRegressor model\n",
        "evaluate_model(xgb_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SAeKwAUvVIj"
      },
      "source": [
        "### [`Optuna`](https://optuna.readthedocs.io/en/stable/index.html) approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KRKTs43XvWtb"
      },
      "outputs": [],
      "source": [
        "#install & import oputuna\n",
        "!pip install optuna\n",
        "# import\n",
        "import optuna\n",
        "\n",
        "# disable logging\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtYzKye3wdBt"
      },
      "outputs": [],
      "source": [
        "# install cross_val_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# import xgbregressor\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYR4Nn9yvzTG"
      },
      "outputs": [],
      "source": [
        "# define objective function\n",
        "def objective(trial):\n",
        "  # define parameter search space\n",
        "  params = {\n",
        "      'early_stopping_rounds': 10,\n",
        "      'eval_metric': 'rmse',\n",
        "      'booster': 'gbtree',\n",
        "      'objective': 'reg:squarederror',\n",
        "      'max_depth': 4,\n",
        "      'gamma': trial.suggest_int('gamma', 1, 5),\n",
        "      'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "      'eta': trial.suggest_float('eta', 0.1, 1.5),\n",
        "      'min_child_weight': trial.suggest_float('min_child_weight', 1, 6),\n",
        "      #'min_child_weight': trial.suggest_int('min_child_weight', 1, 6),\n",
        "      'max_delta_step': trial.suggest_int('max_delta_step', 1, 5),\n",
        "      'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "      'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "      'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
        "      'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0),\n",
        "      'reg_lambda': trial.suggest_int('reg_lambda', 1, 5),\n",
        "      'reg_alpha': trial.suggest_int('reg_alpha', 1, 5)\n",
        "\n",
        "  }\n",
        "\n",
        "  # eval_set for early_stopping should be passed to the\n",
        "  # `fit` method of the XGBRegressor through fit_params parameter of\n",
        "  # corss_val_score\n",
        "  eval = {\n",
        "      'eval_set': [(preprocessor.fit_transform(X_test), y_test)]\n",
        "  }\n",
        "\n",
        "  model = XGBRegressor()\n",
        "  model.set_params(**params)\n",
        "\n",
        "  # perform cross validation on the model with chosen parameters\n",
        "  # return mean score since the function returns a list with scores\n",
        "  score = cross_val_score(model, preprocessor.fit_transform(X_train), y_train,\n",
        "                          fit_params = eval, cv = 3, n_jobs = -1,\n",
        "                          scoring = 'neg_root_mean_squared_error').mean()\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5wfxZbkOCAD",
        "outputId": "a52f8cfb-4e31-4af8-e8fa-ee73f8f3f765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 47 s, sys: 1.04 s, total: 48.1 s\n",
            "Wall time: 5min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# create a study object\n",
        "study = optuna.create_study(direction = 'maximize')\n",
        "\n",
        "# optimize objective function\n",
        "study.optimize(objective, n_trials = 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjHJ8Z-94Sam",
        "outputId": "da59df1b-d9b8-43d9-b7f8-a8148021cef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'gamma': 3, 'n_estimators': 575, 'eta': 1.2480357679620102, 'min_child_weight': 3.515868717621868, 'max_delta_step': 5, 'subsample': 0.7921692143279411, 'colsample_bytree': 0.7541006783737176, 'colsample_bylevel': 0.5585674343982423, 'colsample_bynode': 0.9797116368333302, 'reg_lambda': 2, 'reg_alpha': 5}\n",
            "Best Score: -339.3877151097754\n"
          ]
        }
      ],
      "source": [
        "# print values\n",
        "best_params = study.best_params\n",
        "print(f\"Best Params: {best_params}\")\n",
        "print(f\"Best Score: {study.best_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acnmFu41ZSGf"
      },
      "outputs": [],
      "source": [
        "# create an estimator with the best parameters\n",
        "estimator = XGBRegressor(**best_params)\n",
        "\n",
        "hard_coded_params = {\n",
        "    'early_stopping_rounds': 20,\n",
        "    'eval_metric': 'rmse',\n",
        "    'booster': 'gbtree',\n",
        "    'objective': 'reg:squarederror',\n",
        "    'max_depth': 6,\n",
        "}\n",
        "\n",
        "estimator.set_params(**hard_coded_params)\n",
        "\n",
        "# define pipeline with pre-processor + XGBRegressor\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor), # preprocesor\n",
        "    (\"xgb\", estimator) # estimator\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4iyTnPlaUlQ",
        "outputId": "38736fba-35cb-4bba-fb3a-019bbb627729",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-rmse:639.02968\n",
            "[1]\tvalidation_0-rmse:635.19697\n",
            "[2]\tvalidation_0-rmse:630.97007\n",
            "[3]\tvalidation_0-rmse:626.73179\n",
            "[4]\tvalidation_0-rmse:623.17146\n",
            "[5]\tvalidation_0-rmse:619.55389\n",
            "[6]\tvalidation_0-rmse:615.43307\n",
            "[7]\tvalidation_0-rmse:611.62158\n",
            "[8]\tvalidation_0-rmse:607.57178\n",
            "[9]\tvalidation_0-rmse:603.59193\n",
            "[10]\tvalidation_0-rmse:599.64707\n",
            "[11]\tvalidation_0-rmse:595.64339\n",
            "[12]\tvalidation_0-rmse:591.66602\n",
            "[13]\tvalidation_0-rmse:588.55004\n",
            "[14]\tvalidation_0-rmse:584.71384\n",
            "[15]\tvalidation_0-rmse:580.95556\n",
            "[16]\tvalidation_0-rmse:577.02155\n",
            "[17]\tvalidation_0-rmse:573.21030\n",
            "[18]\tvalidation_0-rmse:569.30037\n",
            "[19]\tvalidation_0-rmse:566.04236\n",
            "[20]\tvalidation_0-rmse:562.15241\n",
            "[21]\tvalidation_0-rmse:558.42992\n",
            "[22]\tvalidation_0-rmse:554.59874\n",
            "[23]\tvalidation_0-rmse:551.21408\n",
            "[24]\tvalidation_0-rmse:547.75932\n",
            "[25]\tvalidation_0-rmse:544.11829\n",
            "[26]\tvalidation_0-rmse:540.40893\n",
            "[27]\tvalidation_0-rmse:536.92881\n",
            "[28]\tvalidation_0-rmse:533.74603\n",
            "[29]\tvalidation_0-rmse:530.10366\n",
            "[30]\tvalidation_0-rmse:526.65165\n",
            "[31]\tvalidation_0-rmse:523.68916\n",
            "[32]\tvalidation_0-rmse:520.08347\n",
            "[33]\tvalidation_0-rmse:516.85910\n",
            "[34]\tvalidation_0-rmse:513.47575\n",
            "[35]\tvalidation_0-rmse:510.21769\n",
            "[36]\tvalidation_0-rmse:507.03431\n",
            "[37]\tvalidation_0-rmse:504.08943\n",
            "[38]\tvalidation_0-rmse:500.90695\n",
            "[39]\tvalidation_0-rmse:497.71369\n",
            "[40]\tvalidation_0-rmse:494.29447\n",
            "[41]\tvalidation_0-rmse:491.10779\n",
            "[42]\tvalidation_0-rmse:488.34603\n",
            "[43]\tvalidation_0-rmse:485.32514\n",
            "[44]\tvalidation_0-rmse:482.47116\n",
            "[45]\tvalidation_0-rmse:479.53536\n",
            "[46]\tvalidation_0-rmse:476.31391\n",
            "[47]\tvalidation_0-rmse:473.92717\n",
            "[48]\tvalidation_0-rmse:470.91925\n",
            "[49]\tvalidation_0-rmse:467.99897\n",
            "[50]\tvalidation_0-rmse:465.04717\n",
            "[51]\tvalidation_0-rmse:462.08307\n",
            "[52]\tvalidation_0-rmse:459.10043\n",
            "[53]\tvalidation_0-rmse:455.93497\n",
            "[54]\tvalidation_0-rmse:453.22707\n",
            "[55]\tvalidation_0-rmse:450.55104\n",
            "[56]\tvalidation_0-rmse:447.61757\n",
            "[57]\tvalidation_0-rmse:444.50161\n",
            "[58]\tvalidation_0-rmse:441.19062\n",
            "[59]\tvalidation_0-rmse:438.57227\n",
            "[60]\tvalidation_0-rmse:435.58919\n",
            "[61]\tvalidation_0-rmse:432.75101\n",
            "[62]\tvalidation_0-rmse:429.87820\n",
            "[63]\tvalidation_0-rmse:426.89523\n",
            "[64]\tvalidation_0-rmse:424.12033\n",
            "[65]\tvalidation_0-rmse:421.43583\n",
            "[66]\tvalidation_0-rmse:419.03079\n",
            "[67]\tvalidation_0-rmse:416.26632\n",
            "[68]\tvalidation_0-rmse:413.59392\n",
            "[69]\tvalidation_0-rmse:411.09155\n",
            "[70]\tvalidation_0-rmse:408.16085\n",
            "[71]\tvalidation_0-rmse:405.30987\n",
            "[72]\tvalidation_0-rmse:403.04031\n",
            "[73]\tvalidation_0-rmse:400.84282\n",
            "[74]\tvalidation_0-rmse:398.36043\n",
            "[75]\tvalidation_0-rmse:396.30380\n",
            "[76]\tvalidation_0-rmse:393.70632\n",
            "[77]\tvalidation_0-rmse:391.19681\n",
            "[78]\tvalidation_0-rmse:388.39581\n",
            "[79]\tvalidation_0-rmse:386.30970\n",
            "[80]\tvalidation_0-rmse:384.29055\n",
            "[81]\tvalidation_0-rmse:382.21464\n",
            "[82]\tvalidation_0-rmse:380.07196\n",
            "[83]\tvalidation_0-rmse:378.09036\n",
            "[84]\tvalidation_0-rmse:375.85398\n",
            "[85]\tvalidation_0-rmse:374.06780\n",
            "[86]\tvalidation_0-rmse:372.25230\n",
            "[87]\tvalidation_0-rmse:370.37108\n",
            "[88]\tvalidation_0-rmse:368.01449\n",
            "[89]\tvalidation_0-rmse:365.89976\n",
            "[90]\tvalidation_0-rmse:364.22384\n",
            "[91]\tvalidation_0-rmse:362.69507\n",
            "[92]\tvalidation_0-rmse:360.81865\n",
            "[93]\tvalidation_0-rmse:358.78665\n",
            "[94]\tvalidation_0-rmse:357.46763\n",
            "[95]\tvalidation_0-rmse:356.13919\n",
            "[96]\tvalidation_0-rmse:354.50468\n",
            "[97]\tvalidation_0-rmse:353.03383\n",
            "[98]\tvalidation_0-rmse:351.01728\n",
            "[99]\tvalidation_0-rmse:349.41244\n",
            "[100]\tvalidation_0-rmse:347.95768\n",
            "[101]\tvalidation_0-rmse:346.80573\n",
            "[102]\tvalidation_0-rmse:345.07584\n",
            "[103]\tvalidation_0-rmse:343.79882\n",
            "[104]\tvalidation_0-rmse:342.71047\n",
            "[105]\tvalidation_0-rmse:341.48774\n",
            "[106]\tvalidation_0-rmse:339.42930\n",
            "[107]\tvalidation_0-rmse:337.52215\n",
            "[108]\tvalidation_0-rmse:336.50329\n",
            "[109]\tvalidation_0-rmse:335.85283\n",
            "[110]\tvalidation_0-rmse:335.33383\n",
            "[111]\tvalidation_0-rmse:334.30373\n",
            "[112]\tvalidation_0-rmse:333.16804\n",
            "[113]\tvalidation_0-rmse:331.77459\n",
            "[114]\tvalidation_0-rmse:330.27001\n",
            "[115]\tvalidation_0-rmse:329.01400\n",
            "[116]\tvalidation_0-rmse:327.83434\n",
            "[117]\tvalidation_0-rmse:326.94687\n",
            "[118]\tvalidation_0-rmse:326.11513\n",
            "[119]\tvalidation_0-rmse:324.77514\n",
            "[120]\tvalidation_0-rmse:323.47596\n",
            "[121]\tvalidation_0-rmse:322.98096\n",
            "[122]\tvalidation_0-rmse:321.79949\n",
            "[123]\tvalidation_0-rmse:321.01155\n",
            "[124]\tvalidation_0-rmse:320.36060\n",
            "[125]\tvalidation_0-rmse:318.88336\n",
            "[126]\tvalidation_0-rmse:318.01986\n",
            "[127]\tvalidation_0-rmse:317.40515\n",
            "[128]\tvalidation_0-rmse:316.95166\n",
            "[129]\tvalidation_0-rmse:316.40157\n",
            "[130]\tvalidation_0-rmse:315.26747\n",
            "[131]\tvalidation_0-rmse:314.08932\n",
            "[132]\tvalidation_0-rmse:313.18421\n",
            "[133]\tvalidation_0-rmse:312.57442\n",
            "[134]\tvalidation_0-rmse:311.24774\n",
            "[135]\tvalidation_0-rmse:310.31551\n",
            "[136]\tvalidation_0-rmse:309.55595\n",
            "[137]\tvalidation_0-rmse:309.09021\n",
            "[138]\tvalidation_0-rmse:308.33873\n",
            "[139]\tvalidation_0-rmse:307.45206\n",
            "[140]\tvalidation_0-rmse:306.91204\n",
            "[141]\tvalidation_0-rmse:306.24543\n",
            "[142]\tvalidation_0-rmse:305.51419\n",
            "[143]\tvalidation_0-rmse:305.41837\n",
            "[144]\tvalidation_0-rmse:304.31823\n",
            "[145]\tvalidation_0-rmse:303.54713\n",
            "[146]\tvalidation_0-rmse:303.17540\n",
            "[147]\tvalidation_0-rmse:302.60509\n",
            "[148]\tvalidation_0-rmse:302.17531\n",
            "[149]\tvalidation_0-rmse:301.98018\n",
            "[150]\tvalidation_0-rmse:301.08826\n",
            "[151]\tvalidation_0-rmse:300.55268\n",
            "[152]\tvalidation_0-rmse:300.09129\n",
            "[153]\tvalidation_0-rmse:299.42302\n",
            "[154]\tvalidation_0-rmse:299.56130\n",
            "[155]\tvalidation_0-rmse:299.27992\n",
            "[156]\tvalidation_0-rmse:298.69498\n",
            "[157]\tvalidation_0-rmse:298.54884\n",
            "[158]\tvalidation_0-rmse:298.70011\n",
            "[159]\tvalidation_0-rmse:298.68134\n",
            "[160]\tvalidation_0-rmse:298.38884\n",
            "[161]\tvalidation_0-rmse:297.69523\n",
            "[162]\tvalidation_0-rmse:296.87039\n",
            "[163]\tvalidation_0-rmse:295.95602\n",
            "[164]\tvalidation_0-rmse:294.95890\n",
            "[165]\tvalidation_0-rmse:294.94575\n",
            "[166]\tvalidation_0-rmse:294.42640\n",
            "[167]\tvalidation_0-rmse:294.44973\n",
            "[168]\tvalidation_0-rmse:294.48370\n",
            "[169]\tvalidation_0-rmse:293.98196\n",
            "[170]\tvalidation_0-rmse:293.08890\n",
            "[171]\tvalidation_0-rmse:292.85801\n",
            "[172]\tvalidation_0-rmse:292.41882\n",
            "[173]\tvalidation_0-rmse:291.56919\n",
            "[174]\tvalidation_0-rmse:291.53748\n",
            "[175]\tvalidation_0-rmse:291.43385\n",
            "[176]\tvalidation_0-rmse:291.36096\n",
            "[177]\tvalidation_0-rmse:291.37850\n",
            "[178]\tvalidation_0-rmse:290.75073\n",
            "[179]\tvalidation_0-rmse:291.10471\n",
            "[180]\tvalidation_0-rmse:290.65451\n",
            "[181]\tvalidation_0-rmse:290.45041\n",
            "[182]\tvalidation_0-rmse:290.52565\n",
            "[183]\tvalidation_0-rmse:290.77019\n",
            "[184]\tvalidation_0-rmse:289.85617\n",
            "[185]\tvalidation_0-rmse:290.00047\n",
            "[186]\tvalidation_0-rmse:289.67175\n",
            "[187]\tvalidation_0-rmse:289.36565\n",
            "[188]\tvalidation_0-rmse:289.01385\n",
            "[189]\tvalidation_0-rmse:288.67827\n",
            "[190]\tvalidation_0-rmse:288.73918\n",
            "[191]\tvalidation_0-rmse:288.46626\n",
            "[192]\tvalidation_0-rmse:287.76350\n",
            "[193]\tvalidation_0-rmse:287.54017\n",
            "[194]\tvalidation_0-rmse:286.78605\n",
            "[195]\tvalidation_0-rmse:287.19663\n",
            "[196]\tvalidation_0-rmse:287.30190\n",
            "[197]\tvalidation_0-rmse:286.65766\n",
            "[198]\tvalidation_0-rmse:287.19009\n",
            "[199]\tvalidation_0-rmse:288.09467\n",
            "[200]\tvalidation_0-rmse:288.42602\n",
            "[201]\tvalidation_0-rmse:289.04033\n",
            "[202]\tvalidation_0-rmse:288.98490\n",
            "[203]\tvalidation_0-rmse:289.51609\n",
            "[204]\tvalidation_0-rmse:289.80234\n",
            "[205]\tvalidation_0-rmse:289.72645\n",
            "[206]\tvalidation_0-rmse:290.04908\n",
            "[207]\tvalidation_0-rmse:290.16709\n",
            "[208]\tvalidation_0-rmse:290.21625\n",
            "[209]\tvalidation_0-rmse:290.67696\n",
            "[210]\tvalidation_0-rmse:290.26402\n",
            "[211]\tvalidation_0-rmse:290.53164\n",
            "[212]\tvalidation_0-rmse:291.33154\n",
            "[213]\tvalidation_0-rmse:291.25200\n",
            "[214]\tvalidation_0-rmse:290.40679\n",
            "[215]\tvalidation_0-rmse:291.12053\n",
            "[216]\tvalidation_0-rmse:289.95441\n",
            "[217]\tvalidation_0-rmse:290.24418\n",
            "CPU times: user 1.98 s, sys: 50.6 ms, total: 2.03 s\n",
            "Wall time: 1.68 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# train the model with best parameters\n",
        "xgb_final = pipeline.fit(X_train, y_train,\n",
        "                         xgb__eval_set = [(preprocessor.fit_transform(X_test), y_test)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhk_zyWsalNq",
        "outputId": "75b1d64c-5fc0-4b51-de11-87b002618cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MSE: 73362.68\n",
            "MAE: 189.36\n",
            "RMSE: 270.86\n",
            "R Squared: 0.816\n"
          ]
        }
      ],
      "source": [
        "# evaluate model\n",
        "evaluate_model(xgb_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save the model**\n",
        "> Here, I will select the model that achieved the best Root Mean Squared Error (RMSE) metrics, thanks to hyperparameter tuning using [`Optuna`](https://optuna.readthedocs.io/en/stable/index.html). This was the XGBRegressor: `xgb_final`"
      ],
      "metadata": {
        "id": "T5Ba3Kz3FiUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model as a pickle file\n",
        "# (will appear on the project file section on colab)\n",
        "filename = './bike-share.pkl'\n",
        "joblib.dump(xgb_final, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqkZto6OGgiw",
        "outputId": "6ef6c602-feb3-4193-c48d-1d40c97e5ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./bike-share.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Now, the model can be loaded whenever needed and used to predict labels for new data. This is often called _scoring_ or _inferencing._  \n",
        "\n",
        "> The model's `predict` method accepts an `array` of observations, hence can be used to generate multiple predictions as a batch. For example, suppose we have a weather forecast for the next five days:"
      ],
      "metadata": {
        "id": "vOFyWo7EE1m2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting for a single feature array"
      ],
      "metadata": {
        "id": "GfcUFqVJNB6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# filename\n",
        "filename = 'bike-share.pkl'\n",
        "# load the saved model\n",
        "loaded_model = joblib.load(filename)\n",
        "\n",
        "# Create a numpy array containing a new observation\n",
        "#X_new = np.array([[1,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]]).astype('float64')\n",
        "X_new = pd.DataFrame(data = np.array([[1,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]]),\n",
        "                     columns = cols,\n",
        "                     dtype='float64')\n",
        "\n",
        "# predict (returns a np.ndarray)\n",
        "results = loaded_model.predict(X_new)\n",
        "\n",
        "for result in results:\n",
        "  print(round(result))\n",
        "\n",
        "# alternatively: print(round(result[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wEdeBOTHUNh",
        "outputId": "3005791f-3826-4c71-e515-d415cc976e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting for multiple feature arrays"
      ],
      "metadata": {
        "id": "6YUhWDVUNfUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An array of features based on five-day weather forecast\n",
        "X_new = pd.DataFrame(data = np.array([[0,1,1,0,0,1,0.344167,0.363625,0.805833,0.160446],\n",
        "                  [0,1,0,1,0,1,0.363478,0.353739,0.696087,0.248539],\n",
        "                  [0,1,0,2,0,1,0.196364,0.189405,0.437273,0.248309],\n",
        "                  [0,1,0,3,0,1,0.2,0.212122,0.590435,0.160296],\n",
        "                  [0,1,0,4,0,1,0.226957,0.22927,0.436957,0.1869]]),\n",
        "                     columns = cols)\n",
        "\n",
        "# Use the model to predict rentals (returns an np.ndarray)\n",
        "results = loaded_model.predict(X_new)\n",
        "\n",
        "print('5-day rental predictions:')\n",
        "for prediction in results:\n",
        "    print(round(prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73lBWpBcF7NG",
        "outputId": "7e7fbc58-c857-49e3-c5f0-1759a7a6e71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-day rental predictions:\n",
            "520\n",
            "570\n",
            "301\n",
            "227\n",
            "346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:**\n",
        ">> The [`pandas.Series.apply()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.apply.html) method below is used to invoke a function (such as a lambda function in our case) on values of `Series` (pandas columns are returned as `Series`)"
      ],
      "metadata": {
        "id": "V-BoeI0ihMoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the predicted values as a new column to X_new\n",
        "X_new['y_hat'] = results\n",
        "\n",
        "# Round off all the values in the y_hat column using a lambda function,\n",
        "# and Series.apply()\n",
        "X_new['y_hat'] = X_new['y_hat'].apply(lambda x: round(x))"
      ],
      "metadata": {
        "id": "zlEvN7KgIdHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, view features and y_hat as a DataFrame\n",
        "X_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pjjLMGqJIzbM",
        "outputId": "55749f42-705e-4f53-c3f9-4a9ae9589d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   season  mnth  holiday  weekday  workingday  weathersit      temp     atemp  \\\n",
              "0     0.0   1.0      1.0      0.0         0.0         1.0  0.344167  0.363625   \n",
              "1     0.0   1.0      0.0      1.0         0.0         1.0  0.363478  0.353739   \n",
              "2     0.0   1.0      0.0      2.0         0.0         1.0  0.196364  0.189405   \n",
              "3     0.0   1.0      0.0      3.0         0.0         1.0  0.200000  0.212122   \n",
              "4     0.0   1.0      0.0      4.0         0.0         1.0  0.226957  0.229270   \n",
              "\n",
              "        hum  windspeed  y_hat  \n",
              "0  0.805833   0.160446    520  \n",
              "1  0.696087   0.248539    570  \n",
              "2  0.437273   0.248309    301  \n",
              "3  0.590435   0.160296    227  \n",
              "4  0.436957   0.186900    346  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-441e5cec-4e74-4427-a6d2-241715b346b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>mnth</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>y_hat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.344167</td>\n",
              "      <td>0.363625</td>\n",
              "      <td>0.805833</td>\n",
              "      <td>0.160446</td>\n",
              "      <td>520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.363478</td>\n",
              "      <td>0.353739</td>\n",
              "      <td>0.696087</td>\n",
              "      <td>0.248539</td>\n",
              "      <td>570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.196364</td>\n",
              "      <td>0.189405</td>\n",
              "      <td>0.437273</td>\n",
              "      <td>0.248309</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.212122</td>\n",
              "      <td>0.590435</td>\n",
              "      <td>0.160296</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.226957</td>\n",
              "      <td>0.229270</td>\n",
              "      <td>0.436957</td>\n",
              "      <td>0.186900</td>\n",
              "      <td>346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-441e5cec-4e74-4427-a6d2-241715b346b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-441e5cec-4e74-4427-a6d2-241715b346b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-441e5cec-4e74-4427-a6d2-241715b346b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb74ec90-95f4-4f0a-ab85-afbee76c9fb2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb74ec90-95f4-4f0a-ab85-afbee76c9fb2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb74ec90-95f4-4f0a-ab85-afbee76c9fb2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ae48b8eb-0308-4195-8fc2-df51f51f43b0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_new')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ae48b8eb-0308-4195-8fc2-df51f51f43b0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_new');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_new",
              "summary": "{\n  \"name\": \"X_new\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mnth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"holiday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44721359549995804,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5811388300841898,\n        \"min\": 0.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"workingday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weathersit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08115014184645644,\n        \"min\": 0.196364,\n        \"max\": 0.363478,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.363478\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"atemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08258561341238557,\n        \"min\": 0.189405,\n        \"max\": 0.363625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.353739\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16165643245475883,\n        \"min\": 0.436957,\n        \"max\": 0.805833,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.696087\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"windspeed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.044716603499147835,\n        \"min\": 0.160296,\n        \"max\": 0.248539,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.248539\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_hat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 146,\n        \"min\": 227,\n        \"max\": 570,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          570\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bL_TT0qQeD-W",
        "i3W-taXAeIKJ",
        "uayksPI-mPhl",
        "AZQWAErjfK0N",
        "OQCETQ__n7NG",
        "qGKYRy_o9Plp",
        "zWApzNfNk15B"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}